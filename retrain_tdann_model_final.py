import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, LSTM, Dropout, Dense
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
import matplotlib.pyplot as plt
import os
import joblib

# Ensure reproducible results (optional)
tf.random.set_seed(42)
np.random.seed(42)

# --- Configuration ---
DATA_FILE = "cleaned_sensor_data.csv"
MODEL_SAVE_PATH = "tdann_pnsm_model.keras"
INPUT_SCALER_SAVE_PATH = "tdann_input_scaler.joblib"
OUTPUT_SCALER_SAVE_PATH = "tdann_output_scaler.joblib"
CROP_ENCODER_SAVE_PATH = "tdann_crop_encoder.joblib"
LOOKBACK_WINDOW = 5
EPOCHS = 50
BATCH_SIZE = 32
VALIDATION_SPLIT = 0.2

# --- Load Your Full Crop Dataset ---
try:
    df = pd.read_csv(DATA_FILE)
    print(f"Data loaded from {DATA_FILE}")
except FileNotFoundError:
    print(f"Error: {DATA_FILE} not found. Please ensure the CSV file is in the same directory.")
    exit()
except Exception as e:
    print(f"Error loading data: {e}")
    exit()

# --- Preprocessing ---

# Ensure 'timestamp' index
if 'timestamp' not in df.columns:
    print("'timestamp' column not found. Generating synthetic timestamps.")
    df['timestamp'] = pd.date_range(start='2024-01-01', periods=len(df), freq='h')
df.set_index('timestamp', inplace=True)

# Ensure 'label' column exists for crop awareness
if 'label' not in df.columns:
    print("Error: 'label' (crop type) column not found. Cannot perform crop-aware training.")
    print("Please ensure your CSV has a 'label' column indicating crop types.")
    exit()

# Convert label to lowercase and strip whitespace
df['label'] = df['label'].str.lower().str.strip()

# One-Hot Encode Crop Labels using sklearn's OneHotEncoder
crop_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
# Fit the encoder on the unique crop labels present in the training data
crop_encoder.fit(df[['label']])
joblib.dump(crop_encoder, CROP_ENCODER_SAVE_PATH) # Save the fitted encoder
print(f"Crop encoder saved to {CROP_ENCODER_SAVE_PATH}")

# Transform the 'label' column into one-hot encoded features
crop_encoded_data = crop_encoder.transform(df[['label']])
# Create a DataFrame from the encoded data with meaningful column names
crop_dummies = pd.DataFrame(crop_encoded_data, columns=crop_encoder.get_feature_names_out(['label']), index=df.index)
df = pd.concat([df, crop_dummies], axis=1)
print(f"Generated {len(crop_dummies.columns)} crop dummy variables using OneHotEncoder.")


# --- Define Features and Targets ---

# Input Features for the TDANN model (these must match the dashboard's `predict_growth` inputs)
base_sensor_features = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']
additional_features = []
if 'growth_factor' in df.columns:
    additional_features.append('growth_factor')
# if 'growth_trigger' in df.columns: # Commented out to align with 30 features currently from Firebase
#     additional_features.append('growth_trigger')

# Use the column names generated by the OneHotEncoder
final_input_features = base_sensor_features + additional_features + crop_encoder.get_feature_names_out(['label']).tolist()


# Target Features for Multi-task output
target_columns = ['soil_moisture', 'light_intensity']
if 'N' in df.columns and 'P' in df.columns and 'K' in df.columns:
    df['npk_sum'] = df['N'] + df['P'] + df['K']
    target_columns.append('npk_sum')
else:
    print("N, P, or K columns missing. NPK sum target will not be used.")

# Ensure all selected features and targets exist in the DataFrame
missing_inputs = [f for f in final_input_features if f not in df.columns]
missing_targets = [t for t in target_columns if t not in df.columns]

if missing_inputs:
    print(f"Missing input features in CSV: {missing_inputs}. Please check your data.")
    exit()
if missing_targets:
    print(f"Missing target features in CSV: {missing_targets}. Please check your data.")
    exit()

print(f"Input features: {final_input_features}")
print(f"Target features: {target_columns}")

# Drop rows with any NaN values in the selected features or targets
df_cleaned = df[final_input_features + target_columns].dropna()
print(f"Original rows: {len(df)}. Rows after dropping NaNs: {len(df_cleaned)}")

if df_cleaned.empty:
    print("No clean data available after dropping NaNs for training. Exiting.")
    exit()

# --- Scaling ---
# Input Scaler
input_scaler = MinMaxScaler()
data_scaled_inputs = input_scaler.fit_transform(df_cleaned[final_input_features])
joblib.dump(input_scaler, INPUT_SCALER_SAVE_PATH)
print(f"Input scaler saved to {INPUT_SCALER_SAVE_PATH}")

# Output Scaler (separate scaler for targets is crucial for multi-output inverse transform)
output_scaler = MinMaxScaler()
data_scaled_targets = output_scaler.fit_transform(df_cleaned[target_columns])
joblib.dump(output_scaler, OUTPUT_SCALER_SAVE_PATH)
print(f"Output scaler saved to {OUTPUT_SCALER_SAVE_PATH}")


# --- Sequence Generation for Multi-Output ---
def create_sequences_multi_output(inputs, targets, lookback=5):
    X, y = [], []
    for i in range(lookback, len(inputs)):
        X.append(inputs[i-lookback:i])
        y.append(targets[i])
    return np.array(X), np.array(y)

X, y = create_sequences_multi_output(data_scaled_inputs, data_scaled_targets, LOOKBACK_WINDOW)

print(f"Generated sequences: X.shape={X.shape}, y.shape={y.shape}")

if X.shape[0] == 0:
    print(f"Not enough data to create sequences with lookback window {LOOKBACK_WINDOW}. Need more than {LOOKBACK_WINDOW} rows.")
    exit()

# --- Build TDANN (LSTM-based) Model with Multi-Output ---
model = Sequential()
model.add(Input(shape=(X.shape[1], X.shape[2])))
model.add(LSTM(128, return_sequences=True, activation='relu'))
model.add(Dropout(0.3))
model.add(LSTM(64, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(len(target_columns), activation='linear'))
model.compile(optimizer='adam', loss='mse')
model.summary()

# --- Train ---
print(f"\n--- Training Model for {EPOCHS} Epochs ---")
history = model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VALIDATION_SPLIT, verbose=1)

# --- Save Model ---
model.save(MODEL_SAVE_PATH)
print(f"New multi-output model trained and saved as {MODEL_SAVE_PATH}")

# --- Optional: Plot Loss ---
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title("TDANN Training Loss (Multi-Output)")
plt.xlabel("Epoch")
plt.ylabel("Mean Squared Error")
plt.legend()
plt.grid(True)
plt.show()


# ==============================================================================
# ðŸŒ¾ New Component Suggestion: Seed Recommender (Already in your dashboard, just for completeness)
# This part is a standalone function that can be integrated into your Streamlit dashboard.
# It doesn't require retraining the TDANN model itself.
# ==============================================================================

def recommend_seeds(ph, temperature, rainfall, soil_moisture=None):
    """
    Suggests suitable crops based on environmental conditions.
    Args:
        ph (float): Current pH value of the soil.
        temperature (float): Current temperature in Celsius.
        rainfall (float): Recent rainfall in mm.
        soil_moisture (float, optional): Current soil moisture percentage.
                                        If available, provides more specific advice.
    Returns:
        str: Recommended crops or general advice.
    """
    recommendations = []

    # pH based recommendations
    if ph < 5.5:
        recommendations.append("acid-tolerant crops like blueberries, potatoes, or specific rice varieties")
    elif ph > 7.5:
        recommendations.append("alkaline-tolerant crops such as asparagus, spinach, or specific varieties of alfalfa")
    else:
        recommendations.append("a wide range of crops thrive in neutral to slightly acidic pH (5.5-7.5), including wheat, maize, and most vegetables")

    # Temperature based recommendations
    if temperature > 35:
        recommendations.append("heat-tolerant crops like millet, sorghum, cotton, or some varieties of beans")
    elif temperature < 15:
        recommendations.append("cold-hardy crops such as wheat (winter varieties), barley, oats, or peas")
    else:
        recommendations.append("warm-season crops like maize, rice (tropical), most vegetables, and fruits")

    # Rainfall based recommendations
    if rainfall < 50: # Low rainfall
        recommendations.append("drought-resistant crops like millet, sorghum, chickpeas, or certain types of beans (e.g., mothbeans)")
    elif rainfall > 200: # High rainfall, potentially waterlogging
        recommendations.append("water-loving crops such as rice, sugarcane, jute, or crops that tolerate temporary waterlogging")
    else:
        recommendations.append("crops suitable for moderate rainfall, including wheat, maize, and many vegetables")

    # Soil Moisture based recommendations (more granular if available)
    if soil_moisture is not None:
        if soil_moisture < 30: # Very dry
            recommendations.append("very drought-tolerant crops (e.g., desert-adapted melons or some herbs)")
        elif soil_moisture > 80: # Very wet, prone to waterlogging
            recommendations.append("semi-aquatic crops or those highly tolerant to waterlogging (e.g., taro, some rice varieties if poorly drained)")

    # Consolidate advice
    if not recommendations:
        return "No specific recommendations, as current conditions are unusual or general."
    return "Based on your conditions, consider: " + ", ".join(recommendations) + ". Please consult local agricultural experts for precise recommendations."

if __name__ == "__main__":
    print("\n--- Seed Recommender Test ---")
    # Simulate some current conditions
    current_ph = 6.2
    current_temp = 28.5
    current_rainfall = 75
    current_soil_moisture = 55 # Optional

    print(f"Conditions: pH={current_ph}, Temp={current_temp}Â°C, Rainfall={current_rainfall}mm, Soil Moisture={current_soil_moisture}%")
    recommended = recommend_seeds(current_ph, current_temp, current_rainfall, current_soil_moisture)
    print(f"Recommendation: {recommended}")

    current_ph_dry = 5.8
    current_temp_dry = 32
    current_rainfall_dry = 20
    current_soil_moisture_dry = 25
    print(f"\nConditions: pH={current_ph_dry}, Temp={current_temp_dry}Â°C, Rainfall={current_rainfall_dry}mm, Soil Moisture={current_soil_moisture_dry}%")
    recommended_dry = recommend_seeds(current_ph_dry, current_temp_dry, current_rainfall_dry, current_soil_moisture_dry)
    print(f"Recommendation: {recommended_dry}")

    current_ph_wet = 7.0
    current_temp_wet = 25
    current_rainfall_wet = 250
    current_soil_moisture_wet = 90
    print(f"\nConditions: pH={current_ph_wet}, Temp={current_temp_wet}Â°C, Rainfall={current_rainfall_wet}mm, Soil Moisture={current_soil_moisture_wet}%")
    recommended_wet = recommend_seeds(current_ph_wet, current_temp_wet, current_rainfall_wet, current_soil_moisture_wet)
    print(f"Recommendation: {recommended_wet}")